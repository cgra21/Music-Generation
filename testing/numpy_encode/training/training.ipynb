{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f2c659-46e1-4ed4-a401-d9ad30cd400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vocab\n",
    "import model as m\n",
    "import importlib\n",
    "importlib.reload(m)\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset\n",
    "importlib.reload(dataset)\n",
    "from dataset import MIDIDataset\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import music21 as ms\n",
    "import utils\n",
    "import torchtext\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc8851d-8cb4-40eb-82bb-a8bd16e08b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.load('vocab.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f897657e-23e3-4536-9187-0b0df4f550b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(vocab[\"<UNK>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c183695d-95e2-4752-b908-9fb8a4fda39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# Create dataloaders for our MIDI files\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent.parent.parent\n",
    "data_folder_path = Path(parent_dir / \"data/midis_v1.2/midis\")\n",
    "file_list = [str(file) for file in data_folder_path.iterdir()]\n",
    "dataset = MIDIDataset(midi_files = file_list, vocab = vocab)\n",
    "\n",
    "def custom_collate_fn(batch, chunk_size=512):\n",
    "    input_chunks = []\n",
    "    target_chunks = []\n",
    "\n",
    "    \n",
    "    for inputs, targets in batch:\n",
    "        inputs = torch.tensor(inputs, dtype=torch.int)\n",
    "        targets = torch.tensor(targets, dtype=torch.int)\n",
    "\n",
    "        num_chunks = max(len(inputs), len(targets)) // chunk_size + 1\n",
    "        \n",
    "        for i in range(num_chunks):\n",
    "            start_idx = i * chunk_size #0, 512, 1024...\n",
    "            end_idx = start_idx + chunk_size #512, 1024, ...\n",
    "\n",
    "            input_chunk = inputs[start_idx:end_idx]\n",
    "            target_chunk = targets[start_idx:end_idx]\n",
    "            \n",
    "            input_chunks.append(input_chunk)\n",
    "            target_chunks.append(target_chunk)\n",
    "            \n",
    "    input_chunks = pad_sequence(input_chunks, batch_first=True, padding_value=vocab[\"<PAD>\"])\n",
    "    target_chunks =  pad_sequence(target_chunks, batch_first=True, padding_value=vocab[\"<PAD>\"])\n",
    "    # Convert to tensor\n",
    "    \n",
    "    return input_chunks, target_chunks\n",
    "\n",
    "def midi_collate_fn(batch):\n",
    "    # Separate input and target sequences\n",
    "    inputs, targets = zip(*batch)\n",
    "    \n",
    "    # Pad sequences so they are all the same length\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return inputs_padded, targets_padded\n",
    "    \n",
    "data_loader = DataLoader(dataset, batch_size = 1, num_workers = 4, shuffle = True, collate_fn=lambda x: custom_collate_fn(x, chunk_size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d18d40-2ebd-4727-942e-bc21824423ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[214,   4,  94,  ...,   4,  76,  50],\n",
      "        [  2,  15,   2,  ...,  93,  90,   3],\n",
      "        [277,  51,  43,  ...,  23,   2,  37],\n",
      "        ...,\n",
      "        [314,   3,   6,  ...,   3,   6,   4],\n",
      "        [  5,   3,   6,  ...,  31,  98,   3],\n",
      "        [ 45,  50, 110,  ...,   1,   1,   1]], dtype=torch.int32), tensor([[  4,  94,   3,  ...,  76,  50,   2],\n",
      "        [ 15,   2,  31,  ...,  90,   3, 277],\n",
      "        [ 51,  43,   3,  ...,   2,  37,   2],\n",
      "        ...,\n",
      "        [  3,   6,  18,  ...,   6,   4,   5],\n",
      "        [  3,   6,   4,  ...,  98,   3,  45],\n",
      "        [ 50, 110,   3,  ...,   1,   1,   1]], dtype=torch.int32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cjgra\\AppData\\Local\\Temp\\ipykernel_13304\\3820126058.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs, dtype=torch.int)\n",
      "C:\\Users\\cjgra\\AppData\\Local\\Temp\\ipykernel_13304\\3820126058.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = torch.tensor(targets, dtype=torch.int)\n"
     ]
    }
   ],
   "source": [
    "for batch in data_loader:\n",
    "    break\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "60dc6a83-087d-470f-a586-215f7fe9811b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__jit_unused_properties__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__prepare_scriptable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'append_token',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_default_index',\n",
       " 'get_extra_state',\n",
       " 'get_itos',\n",
       " 'get_parameter',\n",
       " 'get_stoi',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'insert_token',\n",
       " 'ipu',\n",
       " 'is_jitable',\n",
       " 'load_state_dict',\n",
       " 'lookup_indices',\n",
       " 'lookup_token',\n",
       " 'lookup_tokens',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'set_default_index',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'vocab',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocab testing\n",
    "def tokens_to_indices(tokens, vocab):\n",
    "    return [vocab[token] if token in vocab else vocab[\"<unk>\"] for token in tokens]\n",
    "\n",
    "def indices_to_tokens(ind, vocab):\n",
    "    tokens = vocab.get_itos()\n",
    "    return [tokens[idx] for idx in ind]\n",
    "\n",
    "score = ms.converter.parse(file_list[0])\n",
    "tokens = utils.tokenize(score).split()\n",
    "ind = tokens_to_indices(tokens, vocab)\n",
    "tokens = indices_to_tokens(ind, vocab)\n",
    "dir(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b5b0e3-df5c-484b-acbc-406b00806409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the model\n",
    "vocab_size = len(vocab)\n",
    "model = m.Transformer(\n",
    "    src_vocab_size=vocab_size,\n",
    "    tgt_vocab_size=vocab_size,\n",
    "    d_model=256,\n",
    "    num_heads=4,\n",
    "    num_layers=4,\n",
    "    d_ff=1024,\n",
    "    max_seq_length=100,\n",
    "    dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2145d740-3271-4e77-940e-4db984cbdae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db3ba709-66f6-4719-879b-169028707b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "lr = 5.0\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "model = model.to(device)\n",
    "# Assuming loss_function and optimizer are already defined\n",
    "def train(epochs, data_loader):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        last_loss = 0.0\n",
    "    \n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                output = model(inputs, targets)\n",
    "                output = output.permute(0, 2, 1)\n",
    "                targets = targets.long()\n",
    "                loss = loss_function(output, targets)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            total_loss += loss.item()\n",
    "\n",
    "        scheduler.step()  # Adjust the learning rate based on the scheduler\n",
    "\n",
    "        # Print average loss for the epoch\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(data_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c2c3185-a438-4939-8169-f54b192fe41d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'module' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train(\u001b[38;5;241m3\u001b[39m, data_loader)\n",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, data_loader)\u001b[0m\n\u001b[0;32m     12\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     13\u001b[0m last_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m     16\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\music_gen\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\music_gen\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\music_gen\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m w\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\music_gen\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Popen(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\music_gen\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_context\u001b[38;5;241m.\u001b[39mget_context()\u001b[38;5;241m.\u001b[39mProcess\u001b[38;5;241m.\u001b[39m_Popen(process_obj)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\music_gen\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\music_gen\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(process_obj, to_child)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\music_gen\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[38;5;241m.\u001b[39mdump(obj)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle 'module' object"
     ]
    }
   ],
   "source": [
    "train(3, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c3dd96-45e0-443c-8e02-81535498c03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "492cc81a-963b-4fba-b8ad-dda5091fa3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e907d8c-c28b-446e-afc3-f7fd46dfee33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
